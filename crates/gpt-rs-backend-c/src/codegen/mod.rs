mod emit;
mod profile;
mod types;
mod utils;
mod value_info;

use gpt_rs::backend::conversion::{BufferPlan, ConversionError, ConversionResult};
use gpt_rs::backend::spec::Program;

use crate::dtype::dtype_tag_value;
use crate::kernels;

use self::emit::{emit_instructions, emit_region_function};
use self::profile::{emit_c_profile_metadata, emit_matmul_cache_metadata, OpProfile};
use self::types::{MatmulCacheEntry, ValueKey, ValueStorage};
use self::utils::{c_type, emit_value_array, push_block};
use self::value_info::{
    build_value_infos, emit_tensor_dims, flatten_result_bindings, flatten_value_types,
    is_tuple_type, literal_to_values, output_indices_map, value_info_for_path, LiteralCache,
};

pub fn generate_c_module(
    program: &Program,
    entrypoint: &str,
    plan: &BufferPlan,
) -> ConversionResult<String> {
    let function = program
        .functions
        .iter()
        .find(|f| f.name == program.entry)
        .ok_or_else(|| ConversionError::new("entry function not found"))?;

    if function.parameters.iter().any(is_tuple_type) {
        return Err(ConversionError::new(
            "tuple-typed parameters are not supported by C codegen yet",
        ));
    }

    let func_plan = plan
        .function(&function.name)
        .ok_or_else(|| ConversionError::new("buffer plan missing entry function"))?;

    let result_bindings = flatten_result_bindings(&function.result_ids, &function.results)?;
    let output_indices = output_indices_map(&result_bindings);
    let (value_infos, const_literals) = build_value_infos(
        &function.parameter_ids,
        &function.parameters,
        &function.body,
        func_plan,
        &output_indices,
    )?;

    let mut module = String::new();
    let kernels_src = kernels::emit_c_kernels();
    let header = format!(
        r#"
            // Generated by gpt.rs PTIR conversion (C target)
            #include <stddef.h>
            #include <stdint.h>
            #include <stdlib.h>
            #include <string.h>
            #include <math.h>

            #include <time.h>
            typedef struct {{
              uint32_t dtype;
              uint32_t rank;
              const int64_t* dims;
              void* data;
            }} PtirTensor;

            #define PTIR_DTYPE_F32 0u
            #define PTIR_DTYPE_F16 1u
            #define PTIR_DTYPE_BF16 2u
            #define PTIR_DTYPE_SI32 3u
            #define PTIR_DTYPE_I1 4u

            {kernels_src}
            static int check_tensor(const PtirTensor* t, uint32_t dtype, uint32_t rank, const int64_t* dims) {{
              if (!t || !t->data || !t->dims) {{ return 0; }}
              if (t->dtype != dtype || t->rank != rank) {{ return 0; }}
              for (uint32_t i = 0; i < rank; ++i) {{
                if (t->dims[i] != dims[i]) {{ return 0; }}
              }}
              return 1;
            }}
        "#
    );
    push_block(&mut module, 0, &header);

    let mut body = String::new();
    let mut matmul_profile = OpProfile::default();
    let mut matmul_caches: Vec<MatmulCacheEntry> = Vec::new();

    if !program.regions.is_empty() {
        for region in &program.regions {
            let region_id = region.id.0;
            push_block(
                &mut body,
                0,
                &format!(
                    "static int region_r{region_id}(const void* const* inputs, void* const* outputs);"
                ),
            );
        }
        body.push('\n');
    }

    for region in &program.regions {
        let region_plan = plan
            .region(region.id)
            .ok_or_else(|| ConversionError::new("buffer plan missing region"))?;
        emit_region_function(&mut body, region, region_plan, program, &mut matmul_profile)?;
    }

    let input_specs = flatten_value_types(&function.parameters)?;
    let output_specs = flatten_value_types(&function.results)?;
    let input_dims = emit_tensor_dims(&mut body, "kInputDims", &input_specs)?;
    let output_dims = emit_tensor_dims(&mut body, "kOutputDims", &output_specs)?;

    let input_count = input_specs.len();
    let output_count = output_specs.len();
    let entry_header = format!(
        r#"
            int {entrypoint}(
              const PtirTensor* inputs,
              size_t input_count,
              PtirTensor* outputs,
              size_t output_count) {{
              if (input_count != {input_count}) {{ return -1; }}
              if (output_count != {output_count}) {{ return -1; }}
        "#
    );
    push_block(&mut body, 0, &entry_header);

    for (index, dims_name) in input_dims.iter().enumerate() {
        let spec = &input_specs[index];
        let tag = dtype_tag_value(spec.dtype)?;
        let rank = spec.shape.rank();
        push_block(
            &mut body,
            1,
            &format!(
                "if (!check_tensor(&inputs[{index}], {tag}, {rank}, {dims_name})) {{ return -2; }}"
            ),
        );
    }
    for (index, dims_name) in output_dims.iter().enumerate() {
        let spec = &output_specs[index];
        let tag = dtype_tag_value(spec.dtype)?;
        let rank = spec.shape.rank();
        push_block(
            &mut body,
            1,
            &format!(
                "if (!check_tensor(&outputs[{index}], {tag}, {rank}, {dims_name})) {{ return -3; }}"
            ),
        );
    }

    let mut literal_cache = LiteralCache::default();

    let mut value_keys: Vec<ValueKey> = value_infos.keys().cloned().collect();
    value_keys.sort_by(|a, b| match a.value.0.cmp(&b.value.0) {
        std::cmp::Ordering::Equal => a.path.cmp(&b.path),
        other => other,
    });
    let mut declared = std::collections::HashSet::new();
    for value_key in value_keys.iter() {
        let value_info = value_infos.get(value_key).expect("value id must exist");
        if matches!(value_info.storage, ValueStorage::Alias) {
            continue;
        }
        if !declared.insert(value_info.var.clone()) {
            continue;
        }
        let ctype = c_type(value_info.spec.dtype)?;
        match value_info.storage {
            ValueStorage::Input { index } => {
                let var = &value_info.var;
                push_block(
                    &mut body,
                    1,
                    &format!("const {ctype}* {var} = (const {ctype}*)inputs[{index}].data;"),
                );
            }
            ValueStorage::Output { index } => {
                let var = &value_info.var;
                push_block(
                    &mut body,
                    1,
                    &format!("{ctype}* {var} = ({ctype}*)outputs[{index}].data;"),
                );
            }
            ValueStorage::Temp { .. } => {
                let var = &value_info.var;
                let byte_len = value_info.byte_len;
                let block = format!(
                    r#"
                        {ctype}* {var} = ({ctype}*)malloc({byte_len});
                        if (!{var}) {{ return -4; }}
                    "#
                );
                push_block(&mut body, 1, &block);
            }
            ValueStorage::Const => {
                let const_name = value_info.const_name.as_ref().expect("const name");
                let literal = const_literals
                    .get(&value_key.value)
                    .ok_or_else(|| ConversionError::new("missing const literal"))?
                    .clone();
                let values = literal_to_values(&literal, Some(value_info.elem_count))?;
                let values_str = emit_value_array(&values);
                let var = &value_info.var;
                let block = format!(
                    r#"
                        static const {ctype} {const_name}[] = {{{values_str}}};
                        const {ctype}* {var} = {const_name};
                    "#
                );
                push_block(&mut body, 1, &block);
            }
            ValueStorage::Alias => {}
        }
    }

    if !value_infos.is_empty() {
        body.push('\n');
    }

    emit_instructions(
        &mut body,
        &function.body,
        &value_infos,
        &mut literal_cache,
        program,
        &mut matmul_profile,
        Some(&mut matmul_caches),
    )?;

    if !function.results.is_empty() {
        body.push('\n');
    }

    for (index, binding) in result_bindings.iter().enumerate() {
        let info = value_info_for_path(&value_infos, binding.value, &binding.path)
            .map_err(|_| ConversionError::new("missing result value info"))?;
        if matches!(
            info.storage,
            ValueStorage::Output { .. } | ValueStorage::Alias
        ) {
            continue;
        }
        let var = &info.var;
        let byte_len = info.byte_len;
        push_block(
            &mut body,
            1,
            &format!("memcpy(outputs[{index}].data, {var}, {byte_len});"),
        );
    }

    let mut freed = std::collections::HashSet::new();
    for value_key in value_keys.iter() {
        let value_info = value_infos.get(value_key).expect("value id must exist");
        if matches!(value_info.storage, ValueStorage::Temp { .. })
            && freed.insert(value_info.var.clone())
        {
            let var = &value_info.var;
            push_block(&mut body, 1, &format!("free({var});"));
        }
    }

    push_block(&mut body, 1, "return 0;");
    push_block(&mut body, 0, "}");
    body.push('\n');

    let profile_meta = emit_c_profile_metadata(&matmul_profile);
    let cache_meta = emit_matmul_cache_metadata(&matmul_caches, input_specs.len());
    module = format!("{module}{profile_meta}{cache_meta}{body}");

    Ok(module)
}
